{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd0b777",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d248026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed51148f5f74815a23f49a23173870e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e565c521fc644665be174b6e14085482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"openai/gpt-oss-20b\" \n",
    "# MODEL_ID = \"Qwen/Qwen3-30B-A3B-Instruct-2507-FP8\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, torch_dtype=torch.bfloat16 if torch.cuda.is_available() else None, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fc258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import json_repair\n",
    "import os \n",
    "\n",
    "import sys\n",
    "import re\n",
    "from typing import Dict, Literal\n",
    "\n",
    "# ----De_ID EntitÃ¤ts-Label gemÃ¤ÃŸ GeMTeX-Richtlinien ----\n",
    "Label = Literal[\n",
    "    \"NAME_PATIENT\",\n",
    "    \"NAME_RELATIVE\",\n",
    "    \"NAME_DOCTOR\",\n",
    "    \"NAME_EXT\",\n",
    "    \"NAME_USERNAME\",\n",
    "    \"NAME_TITLE\",\n",
    "    \"DATE_BIRTH\",\n",
    "    \"DATE_DEATH\",\n",
    "    \"DATE\",\n",
    "    \"AGE\",\n",
    "    \"LOCATION_STREET\",\n",
    "    \"LOCATION_CITY\",\n",
    "    \"LOCATION_ZIP\",\n",
    "    \"LOCATION_COUNTRY\",\n",
    "    \"LOCATION_STATE\",\n",
    "    \"LOCATION_HOSPITAL\",\n",
    "    \"LOCATION_ORGANIZATION\",\n",
    "    \"LOCATION_OTHER\",\n",
    "    \"ID\",\n",
    "    \"CONTACT_PHONE\",\n",
    "    \"CONTACT_EMAIL\",\n",
    "    \"CONTACT_FAX\",\n",
    "    \"CONTACT_URL\",\n",
    "    \"PROFESSION\",\n",
    "    \"OTHER\"\n",
    "]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a specialized system for named entity recognition in German clinical texts.\n",
    "Your task is to analyze the user's text and create a JSON object mapping the exact text mentions to their corresponding entity types.\n",
    "\n",
    "Your response MUST be a single, raw JSON object. Do not provide any explanations, analysis, or markdown code fences. Choose the shortest span possible to capture the personal identfiable entities.\n",
    "\n",
    "Here are the entity types:\n",
    "-NAME_PATIENT: The patient's full name (first and/or last).\n",
    "-NAME_RELATIVE: The name of a patient's relative.\n",
    "-NAME_DOCTOR: The name of medical personnel with direct patient contact.\n",
    "-NAME_EXT: The name of a non-medical person (e.g., from administration, legal guardian).\n",
    "-NAME_USERNAME: A system login or KÃ¼rzel (e.g., 'lohrc').\n",
    "-NAME_TITLE: Academic titles (e.g., Prof. Dr., PD), but not functional roles like 'Chefarzt'.\n",
    "\n",
    "-DATE_BIRTH: The patient's complete date of birth.\n",
    "-DATE_DEATH: The patient's complete date of death.\n",
    "-DATE: Any other absolute date (e.g., 15.03.2025, Juni 2024), but not relative dates like 'gestern' or 'vor 2 Jahren'.\n",
    "\n",
    "-AGE: The patient's age (annotate only the number).\n",
    "\n",
    "-LOCATION_STREET: The street name and house number.\n",
    "-LOCATION_CITY: The city, municipality, or district.\n",
    "-LOCATION_ZIP: The postal code.\n",
    "-LOCATION_HOSPITAL: The specific identifying name of a clinic, practice, or named department (e.g., UniversitÃ¤tsklinikum Leipzig), but not generic departments like 'Neurologie' or 'Intensivstation'.\n",
    "-LOCATION_ORGANIZATION: The name of a non-clinical organization (e.g., AOK PLUS).\n",
    "\n",
    "-ID: Alphanumeric identifiers, including patient/case numbers and coded station/room numbers (e.g., 71543356, PSY13, Med 4).\n",
    "\n",
    "-CONTACT_PHONE: A telephone or pager number.\n",
    "-CONTACT_EMAIL: An email address.\n",
    "-CONTACT_FAX: A fax number.\n",
    "-CONTACT_URL: A website URL.\n",
    "\n",
    "-PROFESSION: The patient's profession or job description (e.g., VerkÃ¤uferin, arbeitet im BÃ¼ro).\n",
    "\n",
    "-OTHER: Highly unique person identifiers that do not fit other categories (e.g., BÃ¼rgermeister von Berlin).\n",
    "\n",
    "Example:\n",
    "User Text: 'Wir berichten Ã¼ber Max Mustermann, geb. am 21.03.1950. Der Patient wohnt in der MusterstraÃŸe 1 in 10115 Berlin. Die Aufnahme erfolgte am 01.04.2024 im UniversitÃ¤tsklinikum Leipzig. Kontakt Ã¼ber seine Tochter Anna Mustermann. Behandelnder Arzt ist Prof. Dr. Schmidt.'\n",
    "Your JSON Response: {\"Max Mustermann\":\"NAME_PATIENT\",\"21.03.1950\":\"DATE_BIRTH\",\"MusterstraÃŸe 1\":\"LOCATION_STREET\",\"10115\":\"LOCATION_ZIP\",\"Berlin\":\"LOCATION_CITY\",\"01.04.2024\":\"DATE\",\"UniversitÃ¤tsklinikum Leipzig\":\"LOCATION_HOSPITAL\",\"Anna Mustermann\":\"NAME_RELATIVE\",\"Prof. Dr.\":\"NAME_TITLE\",\"Schmidt\":\"NAME_DOCTOR\"}\n",
    "\"\"\"\n",
    "\n",
    "# ---- Beispieltext zur Verarbeitung ----\n",
    "USER_TEXT = (\n",
    "    \"Die Patientin Erika Musterfrau, 65 Jahre alt und von Beruf VerkÃ¤uferin, wurde am 15.03.2025 vorgestellt. \"\n",
    "    \"Sie wohnt im Birkenweg 5, 80331 MÃ¼nchen. \"\n",
    "    \"Einlieferung durch den Notarzt Dr. Klaus Meier vom Klinikum Rechts der Isar. \"\n",
    "    \"Ihre Fall-Nr. lautet 9876543. \"\n",
    "    \"Telefonischer Kontakt ist unter 089-123456 mÃ¶glich.\"\n",
    ")\n",
    "\n",
    "# Pydantic v1/v2 compatibility (RootModel in v2, __root__ in v1)\n",
    "try:\n",
    "    from pydantic import RootModel  # v2\n",
    "    class Entities(RootModel[Dict[str, Label]]):\n",
    "        pass\n",
    "    def validate_payload(payload: dict) -> Dict[str, str]:\n",
    "        return Entities(payload).root\n",
    "except Exception:\n",
    "    from pydantic import BaseModel  # v1\n",
    "    class Entities(BaseModel):\n",
    "        __root__: Dict[str, Label]\n",
    "    def validate_payload(payload: dict) -> Dict[str, str]:\n",
    "        return Entities(__root__=payload).__root__\n",
    "    \n",
    "def build_input(tokenizer, text: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    \n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        return tokenizer.apply_chat_template(\n",
    "            messages, add_generation_prompt=True, return_tensors=\"pt\", reasoning_effort=\"medium\"\n",
    "        )\n",
    "\n",
    "# Helper to pull ONLY the assistant final channel from the raw text\n",
    "FINAL_BLOCK_RE = re.compile(\n",
    "    r\"<\\|start\\|>assistant<\\|channel\\|>final<\\|message\\>(.*?)(?:<\\|end\\|>|<\\|return\\|>)\",\n",
    "    re.DOTALL,\n",
    ")\n",
    "\n",
    "def extract_final_channel(text: str) -> str:\n",
    "    m = FINAL_BLOCK_RE.search(text)\n",
    "    if not m:\n",
    "        return text\n",
    "    return m.group(1).strip()\n",
    "\n",
    "def parse_json_or_repair(json_str: str):\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            repaired = json_repair.repair_json(json_str)\n",
    "            return json.loads(repaired)\n",
    "        except Exception as e:\n",
    "            # Fallback: always return valid JSON by wrapping the raw content\n",
    "            return {\n",
    "                \"raw\": json_str\n",
    "            }\n",
    "    \n",
    "# ---- Hauptverarbeitung ----\n",
    "txt_input_folder = \"data/fictive_txt\"\n",
    "json_output_folder = \"LLM_output/openai/gpt-oss-20b/fictive_new\"\n",
    "for filename in os.listdir(txt_input_folder):\n",
    "    with open(os.path.join(txt_input_folder, filename), 'r', encoding='utf-8') as f:\n",
    "        USER_TEXT = f.read()\n",
    "        input_ids = build_input(tokenizer, USER_TEXT).to(model.device)\n",
    "\n",
    "        gen_kwargs = dict(\n",
    "            max_new_tokens=20000,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.15,            # gentle anti-loop // might also try 1.3\n",
    "            # no_repeat_ngram_size=6,             # blocks exact-phrase loops\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(input_ids, **gen_kwargs)\n",
    "        # # Assistant-only tokens\n",
    "        # gen_ids = out[0][input_ids.shape[-1]:]\n",
    "\n",
    "        # # Keep special tokens so channel tags like <|start|>â€¦<|channel|>analysis show up\n",
    "        # raw = tokenizer.decode(gen_ids, skip_special_tokens=False).strip()\n",
    "\n",
    "        # # ðŸ”Ž (A) simple: print the entire raw completion with channels/tags\n",
    "        # print(\"\\n--- RAW COMPLETION (with channels & tags) ---\\n\", raw, \"\\n--- END RAW ---\\n\", file=sys.stderr)\n",
    "\n",
    "        # Slice off the prompt part\n",
    "        gen_ids = out[0][input_ids.shape[-1]:]\n",
    "        raw = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "        \n",
    "        # Extract only the final channel \n",
    "        final_text = extract_final_channel(raw)\n",
    "        try:\n",
    "            payload = parse_json_or_repair(final_text)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to parse JSON from model output.\\n--- RAW OUTPUT ---\\n\", raw, file=sys.stderr)\n",
    "            payload = final_text\n",
    "            raise\n",
    "\n",
    "        # Save the converted data to a JSON file\n",
    "        json_filename = filename.replace('.txt', '.json')\n",
    "        json_filepath = os.path.join(json_output_folder, json_filename)\n",
    "        with open(json_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            \n",
    "# Validierung der JSON-Dateien im Ausgabeordner mit Pydantic (structure + allowed labels)\n",
    "for json_filename in os.listdir(json_output_folder):\n",
    "    json_filepath = os.path.join(json_output_folder, json_filename)\n",
    "    try:\n",
    "        # JSON-Datei Ã¶ffnen und Inhalt laden\n",
    "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "            data_to_validate = json.load(f)\n",
    "        # Pydantic-Validierung durchfÃ¼hren \n",
    "        validated_data = validate_payload(data_to_validate)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  -> FEHLER: Konnte JSON aus {json_filename} nicht lesen. Fehler: {e}\", file=sys.stderr)\n",
    "    except Exception as e: # FÃ¤ngt Pydantic-Validierungsfehler ab\n",
    "        print(f\"  -> FEHLER: {json_filename} hat die Pydantic-Validierung nicht bestanden.\", file=sys.stderr)\n",
    "        print(f\"     Pydantic-Fehler: {e}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import json_repair\n",
    "import os \n",
    "\n",
    "import sys\n",
    "import re\n",
    "from typing import Dict, Literal\n",
    "json_output_folder = \"LLM_output/openai/gpt-oss-20b/fictive\"\n",
    "\n",
    "# ----De_ID EntitÃ¤ts-Label gemÃ¤ÃŸ GeMTeX-Richtlinien ----\n",
    "Label = Literal[\n",
    "    \"NAME_PATIENT\",\n",
    "    \"NAME_RELATIVE\",\n",
    "    \"NAME_DOCTOR\",\n",
    "    \"NAME_EXT\",\n",
    "    \"NAME_USERNAME\",\n",
    "    \"NAME_TITLE\",\n",
    "    \"DATE_BIRTH\",\n",
    "    \"DATE_DEATH\",\n",
    "    \"DATE\",\n",
    "    \"AGE\",\n",
    "    \"LOCATION_STREET\",\n",
    "    \"LOCATION_CITY\",\n",
    "    \"LOCATION_ZIP\",\n",
    "    \"LOCATION_COUNTRY\",\n",
    "    \"LOCATION_STATE\",\n",
    "    \"LOCATION_HOSPITAL\",\n",
    "    \"LOCATION_ORGANIZATION\",\n",
    "    \"LOCATION_OTHER\",\n",
    "    \"ID\",\n",
    "    \"CONTACT_PHONE\",\n",
    "    \"CONTACT_EMAIL\",\n",
    "    \"CONTACT_FAX\",\n",
    "    \"CONTACT_URL\",\n",
    "    \"PROFESSION\",\n",
    "    \"OTHER\"\n",
    "]\n",
    "\n",
    "# Pydantic v1/v2 compatibility (RootModel in v2, __root__ in v1)\n",
    "try:\n",
    "    from pydantic import RootModel  # v2\n",
    "    class Entities(RootModel[Dict[str, Label]]):\n",
    "        pass\n",
    "    def validate_payload(payload: dict) -> Dict[str, str]:\n",
    "        return Entities(payload).root\n",
    "except Exception:\n",
    "    from pydantic import BaseModel  # v1\n",
    "    class Entities(BaseModel):\n",
    "        __root__: Dict[str, Label]\n",
    "    def validate_payload(payload: dict) -> Dict[str, str]:\n",
    "        return Entities(__root__=payload).__root__\n",
    "    \n",
    "# Validierung der JSON-Dateien im Ausgabeordner mit Pydantic (structure + allowed labels)\n",
    "for json_filename in os.listdir(json_output_folder):\n",
    "    json_filepath = os.path.join(json_output_folder, json_filename)\n",
    "    try:\n",
    "        # JSON-Datei Ã¶ffnen und Inhalt laden\n",
    "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "            data_to_validate = json.load(f)\n",
    "        # Pydantic-Validierung durchfÃ¼hren \n",
    "        validated_data = validate_payload(data_to_validate)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  -> FEHLER: Konnte JSON aus {json_filename} nicht lesen. Fehler: {e}\", file=sys.stderr)\n",
    "    except Exception as e: # FÃ¤ngt Pydantic-Validierungsfehler ab\n",
    "        print(f\"  -> FEHLER: {json_filename} hat die Pydantic-Validierung nicht bestanden.\", file=sys.stderr)\n",
    "        print(f\"     Pydantic-Fehler: {e}\", file=sys.stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
