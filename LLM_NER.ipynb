{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd0b777",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d248026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bdec91610f4d7aa42d0f34df6f8e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"openai/gpt-oss-20b\" \n",
    "# MODEL_ID = \"Qwen/Qwen3-30B-A3B-Instruct-2507-FP8\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, torch_dtype=torch.bfloat16 if torch.cuda.is_available() else None, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fc258",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 148\u001b[39m\n\u001b[32m    140\u001b[39m gen_kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    141\u001b[39m     max_new_tokens=\u001b[32m10000\u001b[39m,\n\u001b[32m    142\u001b[39m     do_sample=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m     eos_token_id=tokenizer.eos_token_id,\n\u001b[32m    146\u001b[39m )\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# # Assistant-only tokens\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# gen_ids = out[0][input_ids.shape[-1]:]\u001b[39;00m\n\u001b[32m    151\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    157\u001b[39m \n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# Slice off the prompt part\u001b[39;00m\n\u001b[32m    159\u001b[39m gen_ids = out[\u001b[32m0\u001b[39m][input_ids.shape[-\u001b[32m1\u001b[39m]:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/generation/utils.py:2629\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2621\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2622\u001b[39m         input_ids=input_ids,\n\u001b[32m   2623\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2624\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2625\u001b[39m         **model_kwargs,\n\u001b[32m   2626\u001b[39m     )\n\u001b[32m   2628\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2640\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2641\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2642\u001b[39m         input_ids=input_ids,\n\u001b[32m   2643\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2644\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2645\u001b[39m         **model_kwargs,\n\u001b[32m   2646\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/generation/utils.py:3613\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3611\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3612\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3613\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3616\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3617\u001b[39m     outputs,\n\u001b[32m   3618\u001b[39m     model_kwargs,\n\u001b[32m   3619\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3620\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/utils/generic.py:959\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    957\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    958\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    961\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:658\u001b[39m, in \u001b[36mGptOssForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_router_logits, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    653\u001b[39m output_router_logits = (\n\u001b[32m    654\u001b[39m     output_router_logits \u001b[38;5;28;01mif\u001b[39;00m output_router_logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_router_logits\n\u001b[32m    655\u001b[39m )\n\u001b[32m    657\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m outputs: MoeModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_router_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_router_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/utils/generic.py:1083\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1080\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1081\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:491\u001b[39m, in \u001b[36mGptOssModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m MoeModelOutputWithPast(\n\u001b[32m    503\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    504\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    505\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:369\u001b[39m, in \u001b[36mGptOssDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[32m    368\u001b[39m residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m hidden_states, _ = \u001b[38;5;28mself\u001b[39m.mlp(hidden_states)  \u001b[38;5;66;03m# diff with llama: router scores\u001b[39;00m\n\u001b[32m    371\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/NER/lib/python3.11/site-packages/torch/nn/modules/module.py:1778\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     forward_call = (\u001b[38;5;28mself\u001b[39m._slow_forward \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_tracing_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward)\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json_repair\n",
    "import os \n",
    "\n",
    "import sys\n",
    "import re\n",
    "from typing import Dict, Literal\n",
    "\n",
    "# ----De_ID Entitäts-Label gemäß GeMTeX-Richtlinien ----\n",
    "Label = Literal[\n",
    "    \"NAME_PATIENT\",\n",
    "    \"NAME_RELATIVE\",\n",
    "    \"NAME_DOCTOR\",\n",
    "    \"NAME_EXT\",\n",
    "    \"NAME_USERNAME\",\n",
    "    \"NAME_TITLE\",\n",
    "    \"DATE_BIRTH\",\n",
    "    \"DATE_DEATH\",\n",
    "    \"DATE\",\n",
    "    \"AGE\",\n",
    "    \"LOCATION_STREET\",\n",
    "    \"LOCATION_CITY\",\n",
    "    \"LOCATION_ZIP\",\n",
    "    \"LOCATION_COUNTRY\",\n",
    "    \"LOCATION_STATE\",\n",
    "    \"LOCATION_HOSPITAL\",\n",
    "    \"LOCATION_ORGANIZATION\",\n",
    "    \"LOCATION_OTHER\",\n",
    "    \"ID\",\n",
    "    \"CONTACT_PHONE\",\n",
    "    \"CONTACT_EMAIL\",\n",
    "    \"CONTACT_FAX\",\n",
    "    \"CONTACT_URL\",\n",
    "    \"PROFESSION\",\n",
    "    \"OTHER\"\n",
    "]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a specialized system for named entity recognition in German clinical texts.\n",
    "Your task is to analyze the user's text and create a JSON object mapping the exact text mentions to their corresponding entity types.\n",
    "\n",
    "Your response MUST be a single, raw JSON object. Do not provide any explanations, analysis, or markdown code fences. Choose the shortest span possible to capture the personal identfiable entities.\n",
    "\n",
    "Here are the entity types:\n",
    "-NAME_PATIENT: The patient's full name (first and/or last).\n",
    "-NAME_RELATIVE: The name of a patient's relative.\n",
    "-NAME_DOCTOR: The name of medical personnel with direct patient contact.\n",
    "-NAME_EXT: The name of a non-medical person (e.g., from administration, legal guardian).\n",
    "-NAME_USERNAME: A system login or Kürzel (e.g., 'lohrc').\n",
    "-NAME_TITLE: Academic titles (e.g., Prof. Dr., PD), but not functional roles like 'Chefarzt'.\n",
    "\n",
    "-DATE_BIRTH: The patient's complete date of birth.\n",
    "-DATE_DEATH: The patient's complete date of death.\n",
    "-DATE: Any other absolute date (e.g., 15.03.2025, Juni 2024), but not relative dates like 'gestern' or 'vor 2 Jahren'.\n",
    "\n",
    "-AGE: The patient's age (annotate only the number).\n",
    "\n",
    "-LOCATION_STREET: The street name and house number.\n",
    "-LOCATION_CITY: The city, municipality, or district.\n",
    "-LOCATION_ZIP: The postal code.\n",
    "-LOCATION_HOSPITAL: The specific identifying name of a clinic, practice, or named department (e.g., Universitätsklinikum Leipzig), but not generic departments like 'Neurologie' or 'Intensivstation'.\n",
    "-LOCATION_ORGANIZATION: The name of a non-clinical organization (e.g., AOK PLUS).\n",
    "\n",
    "-ID: Alphanumeric identifiers, including patient/case numbers and coded station/room numbers (e.g., 71543356, PSY13, Med 4).\n",
    "\n",
    "-CONTACT_PHONE: A telephone or pager number.\n",
    "-CONTACT_EMAIL: An email address.\n",
    "-CONTACT_FAX: A fax number.\n",
    "-CONTACT_URL: A website URL.\n",
    "\n",
    "-PROFESSION: The patient's profession or job description (e.g., Verkäuferin, arbeitet im Büro).\n",
    "\n",
    "-OTHER: Highly unique person identifiers that do not fit other categories (e.g., Bürgermeister von Berlin).\n",
    "\n",
    "Example:\n",
    "User Text: 'Wir berichten über Max Mustermann, geb. am 21.03.1950. Der Patient wohnt in der Musterstraße 1 in 10115 Berlin. Die Aufnahme erfolgte am 01.04.2024 im Universitätsklinikum Leipzig. Kontakt über seine Tochter Anna Mustermann. Behandelnder Arzt ist Prof. Dr. Schmidt.'\n",
    "Your JSON Response: {\"Max Mustermann\":\"NAME_PATIENT\",\"21.03.1950\":\"DATE_BIRTH\",\"Musterstraße 1\":\"LOCATION_STREET\",\"10115\":\"LOCATION_ZIP\",\"Berlin\":\"LOCATION_CITY\",\"01.04.2024\":\"DATE\",\"Universitätsklinikum Leipzig\":\"LOCATION_HOSPITAL\",\"Anna Mustermann\":\"NAME_RELATIVE\",\"Prof. Dr.\":\"NAME_TITLE\",\"Schmidt\":\"NAME_DOCTOR\"}\n",
    "\"\"\"\n",
    "\n",
    "# ---- Beispieltext zur Verarbeitung ----\n",
    "USER_TEXT = (\n",
    "    \"Die Patientin Erika Musterfrau, 65 Jahre alt und von Beruf Verkäuferin, wurde am 15.03.2025 vorgestellt. \"\n",
    "    \"Sie wohnt im Birkenweg 5, 80331 München. \"\n",
    "    \"Einlieferung durch den Notarzt Dr. Klaus Meier vom Klinikum Rechts der Isar. \"\n",
    "    \"Ihre Fall-Nr. lautet 9876543. \"\n",
    "    \"Telefonischer Kontakt ist unter 089-123456 möglich.\"\n",
    ")\n",
    "\n",
    "# Pydantic v1/v2 compatibility (RootModel in v2, __root__ in v1)\n",
    "try:\n",
    "    from pydantic import RootModel  # v2\n",
    "    class Entities(RootModel[Dict[str, Label]]):\n",
    "        pass\n",
    "    def validate_payload(payload: dict) -> Dict[str, str]:\n",
    "        return Entities(payload).root\n",
    "except Exception:\n",
    "    from pydantic import BaseModel  # v1\n",
    "    class Entities(BaseModel):\n",
    "        __root__: Dict[str, Label]\n",
    "    def validate_payload(payload: dict) -> Dict[str, str]:\n",
    "        return Entities(__root__=payload).__root__\n",
    "    \n",
    "def build_input(tokenizer, text: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    \n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        return tokenizer.apply_chat_template(\n",
    "            messages, add_generation_prompt=True, return_tensors=\"pt\", reasoning_effort=\"medium\"\n",
    "        )\n",
    "\n",
    "# Helper to pull ONLY the assistant final channel from the raw text\n",
    "FINAL_BLOCK_RE = re.compile(\n",
    "    r\"<\\|start\\|>assistant<\\|channel\\|>final<\\|message\\>(.*?)(?:<\\|end\\|>|<\\|return\\|>)\",\n",
    "    re.DOTALL,\n",
    ")\n",
    "\n",
    "def extract_final_channel(text: str) -> str:\n",
    "    m = FINAL_BLOCK_RE.search(text)\n",
    "    if not m:\n",
    "        return text\n",
    "    return m.group(1).strip()\n",
    "\n",
    "def parse_json_or_repair(json_str: str):\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        repaired = json_repair.repair_json(json_str)\n",
    "        return json.loads(repaired)\n",
    "    \n",
    "# ---- Hauptverarbeitung ----\n",
    "txt_input_folder = \"data/fictive_txt\"\n",
    "json_output_folder = \"LLM_output/openai/gpt-oss-20b/fictive\"\n",
    "for filename in os.listdir(txt_input_folder):\n",
    "    with open(os.path.join(txt_input_folder, filename), 'r', encoding='utf-8') as f:\n",
    "        USER_TEXT = f.read()\n",
    "        input_ids = build_input(tokenizer, USER_TEXT).to(model.device)\n",
    "\n",
    "        gen_kwargs = dict(\n",
    "            max_new_tokens=10000,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.15,            # gentle anti-loop\n",
    "            # no_repeat_ngram_size=6,             # blocks exact-phrase loops\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(input_ids, **gen_kwargs)\n",
    "        # # Assistant-only tokens\n",
    "        # gen_ids = out[0][input_ids.shape[-1]:]\n",
    "\n",
    "        # # Keep special tokens so channel tags like <|start|>…<|channel|>analysis show up\n",
    "        # raw = tokenizer.decode(gen_ids, skip_special_tokens=False).strip()\n",
    "\n",
    "        # # 🔎 (A) simple: print the entire raw completion with channels/tags\n",
    "        # print(\"\\n--- RAW COMPLETION (with channels & tags) ---\\n\", raw, \"\\n--- END RAW ---\\n\", file=sys.stderr)\n",
    "\n",
    "        # Slice off the prompt part\n",
    "        gen_ids = out[0][input_ids.shape[-1]:]\n",
    "        raw = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "        \n",
    "        # Extract only the final channel \n",
    "        final_text = extract_final_channel(raw)\n",
    "        try:\n",
    "            payload = parse_json_or_repair(final_text)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to parse JSON from model output.\\n--- RAW OUTPUT ---\\n\", raw, file=sys.stderr)\n",
    "            raise\n",
    "\n",
    "        # Save the converted data to a JSON file\n",
    "        json_filename = filename.replace('.txt', '.json')\n",
    "        json_filepath = os.path.join(json_output_folder, json_filename)\n",
    "        with open(json_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            \n",
    "# Validierung der JSON-Dateien im Ausgabeordner mit Pydantic (structure + allowed labels)\n",
    "for json_filename in os.listdir(json_output_folder):\n",
    "    json_filepath = os.path.join(json_output_folder, json_filename)\n",
    "    try:\n",
    "        # JSON-Datei öffnen und Inhalt laden\n",
    "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "            data_to_validate = json.load(f)\n",
    "        # Pydantic-Validierung durchführen \n",
    "        validated_data = validate_payload(data_to_validate)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  -> FEHLER: Konnte JSON aus {json_filename} nicht lesen. Fehler: {e}\", file=sys.stderr)\n",
    "    except Exception as e: # Fängt Pydantic-Validierungsfehler ab\n",
    "        print(f\"  -> FEHLER: {json_filename} hat die Pydantic-Validierung nicht bestanden.\", file=sys.stderr)\n",
    "        print(f\"     Pydantic-Fehler: {e}\", file=sys.stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
